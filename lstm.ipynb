{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler # 적절한 타이밍에 데이터 셰이프를 변환하거나, 데이터를 플롯하거나 표준화 가능\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('./data/train_x_df.csv')\n",
    "test_x = pd.read_csv('./data/test_x_df.csv')\n",
    "train_y = pd.read_csv('./data/train_y_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간값 구하는 함수\n",
    "def getMidprice(sample_id, df):\n",
    "  sample_id_df=df[df['sample_id']==sample_id]\n",
    "\n",
    "  high_prices = sample_id_df.loc[:, 'high'].values\n",
    "  low_prices = sample_id_df.loc[:, 'low'].values\n",
    "  mid_prices = (high_prices + low_prices)/2.0\n",
    "  \n",
    "  mid_prices=mid_prices.reshape(-1, 1) # scaler.fit_transform\n",
    "\n",
    "  return mid_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 검증 데이터셋 생성 함수\n",
    "# look_back : 관측값에서 유지해야 할 가격의 수, 예측전 지난 n개의 가격을 돌아보도록 함\n",
    "# foresight : 각 train 시퀀스에 대한 라벨이 시퀀스 다음 n+1분의 가격\n",
    "# dataset변수의 길이를 조정해서 넣어서 train 및 validation 각각 생성\n",
    "def create_train_dataset(dataset, look_back=210, foresight=119):\n",
    "  X, Y = [], []\n",
    "\n",
    "  for i in range(len(dataset)-look_back-foresight) :\n",
    "    # 관찰 값을 형성하는 특징으로 과거 210개의 가격 시퀀스 지정\n",
    "    obs=dataset[i:(i+look_back), 0]\n",
    "    # 시퀀스 추가\n",
    "    X.append(obs)\n",
    "    # 210개 가격의 한 시퀀스의 120분 후 가격 \n",
    "    Y.append(dataset[i+(look_back+foresight), 0])\n",
    "\n",
    "  return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 생성 함수\n",
    "def create_test_dataset(dataset, look_back=210):\n",
    "  x_test = []\n",
    "\n",
    "  for i in range(len(dataset)-look_back) :\n",
    "    # 관찰 값을 형성하는 특징으로 과거 210개의 가격 시퀀스 지정\n",
    "    obs=dataset[i:(i+look_back), 0]\n",
    "    # 시퀀스 추가\n",
    "    x_test.append(obs)\n",
    "\n",
    "  return np.array(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 및 예측\n",
    "- 대회에서 제공한 train dataset을 사용하지 않고 test 데이터만을 통해 예측했습니다.\n",
    "- 최대 예측값이 1보다 작으면 sell_time을 0으로 설정 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=test_x['sample_id'].unique()\n",
    "pred_selling_time = []\n",
    "\n",
    "for idx, id in tqdm(enumerate(samples)):\n",
    "  print(idx, \"/ sample_id :\", id)\n",
    "  print(\"get mid price\")\n",
    "  # sample_id에 대한 중간값으로 학습 및 테스트 데이터 생성\n",
    "  x_mid_prices = getMidprice(id, test_x)\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  print(\"windowed normalization\")\n",
    "  ### 윈도우 방식 표준화\n",
    "  # 데이터를 표준화하기 위한 윈도우 크기\n",
    "  normalization_window = 138\n",
    "\n",
    "  # 표준화 범위\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "  x_win_prices=x_mid_prices.copy()\n",
    "  # 한 번에 138개의 x_train 데이터별로 윈도우 표준화\n",
    "  for i in range(0, 1380, normalization_window):\n",
    "    # 현재 윈도우에 대해 스케일러 객체를 데이터에 적용\n",
    "    scaler.fit(x_mid_prices[i:i+normalization_window, :])\n",
    "    # 현재 윈도우의 데이터를 선택한 특징 범위(0~1)의 데이터로 변환\n",
    "    x_win_prices[i:i+normalization_window,:] = scaler.transform(x_mid_prices[i:i+normalization_window,:])\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  print(\"Exponential smoothing\")\n",
    "  # 지수 평활법 - 최근 사건이 과거보다 현재 데이터에 더 많은 영향을 주도록\n",
    "  # 데이터에 포함된 고주파 노이즈 제거\n",
    "\n",
    "  Smoothing=0 # 평활화 값을 0으로 초기화\n",
    "  gamma = 0.3 # 소멸 계수\n",
    "  x_sm_prices=[]\n",
    "\n",
    "  # x_train데이터 평활화\n",
    "  for a in range(1380):\n",
    "    # 평활화 값 업데이트\n",
    "    Smoothing = gamma*x_win_prices[a]+(1-gamma)*Smoothing\n",
    "    # 평활화 값으로 데이터 포인트 값을 대체\n",
    "    x_sm_prices.append(Smoothing)\n",
    "\n",
    "  x_sm_prices=np.array(x_sm_prices).reshape(-1, 1)\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  print(\"get train and validation data set\")\n",
    "  x_train, y_train = createTrainValid(x_sm_prices[:1259])\n",
    "  x_validation, y_validation = createTrainValid(x_sm_prices)\n",
    "  x_test = createTestset(x_sm_prices)\n",
    "  \n",
    "  ##############################################################################\n",
    "\n",
    "  print(\"reshaping\")\n",
    "  x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "  y_train = np.reshape(y_train, (y_train.shape[0], 1, 1)) \n",
    "\n",
    "  x_validation = np.reshape(x_validation, (x_validation.shape[0], 1, x_validation.shape[1]))\n",
    "  y_validation = np.reshape(y_validation, (y_validation.shape[0], 1, 1)) \n",
    "\n",
    "  x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "  ##############################################################################\n",
    "\n",
    "  print(\"training\")\n",
    "  # seed 값 설정\n",
    "  seed = 0\n",
    "  np.random.seed(seed)\n",
    "  tf.random.set_seed(3)\n",
    "\n",
    "  model=Sequential()\n",
    "  model.add(LSTM(480, input_shape=(1, 210), dropout=0.1, recurrent_dropout=0.2, return_sequences=True))\n",
    "  model.add(LSTM(480, dropout=0.1, recurrent_dropout=0.2, return_sequences=True))\n",
    "  model.add(LSTM(480, dropout=0.1, recurrent_dropout=0.2))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "\n",
    "  model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "  early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "  # 모델의 실행\n",
    "  history = model.fit(x_train, y_train, validation_data=(x_validation, y_validation), \n",
    "                      epochs=50, batch_size=3000, verbose=0, callbacks=[early_stopping_callback])\n",
    "\n",
    "  preds = model.predict(x_test)[-120:]\n",
    "  preds = preds.flatten()\n",
    "\n",
    "  st = 0 \n",
    "  if scaler.inverse_transform(preds.max().reshape(-1,1))/x_mid_prices[-1,0] > 1:\n",
    "    st = preds.argmax()\n",
    "  pred_selling_time.append(st)\n",
    "\n",
    "pred_selling_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['sample_id'] = range(x_train_open.shape[0], x_train_open.shape[0]+x_test_open.shape[0])\n",
    "submission['buy_quantity'] = 1\n",
    "submission['sell_time'] = pred_selling_time\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('submission_lstm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}